#velo_service: pipeline de prÃ©paration des donnÃ©es.
# services/velo_service.py

import pandas as pd
import numpy as np
import os

class VeloPipeline:
    def __init__(self, df_velo: pd.DataFrame, df_meteo: pd.DataFrame = None):
        self.df_velo = df_velo.copy()
        self.df_meteo = df_meteo.copy() if df_meteo is not None else None
        self.duration = None
        self.df_clean = None
        self.df_365 = None
        self.df_200 = None
        self.df_100 = None

    # ---------------------------------------------------------
    # 1ï¸ Nettoyage des donnÃ©es
    # ---------------------------------------------------------
    def clean_data(self):
        df = self.df_velo.drop_duplicates().copy()
        df['datetime'] = pd.to_datetime(df['datetime'])
        df['intensity'] = pd.to_numeric(df['intensity'], errors='coerce')
        df['hour'] = df['datetime'].dt.hour
        df['weekday'] = df['datetime'].dt.weekday
        df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)

        df['intensity'] = df.groupby('counter_id')['intensity'].transform(
            lambda x: np.where(x > 300, np.nanmedian(x), x)
        )
        self.df_clean = df
        return df

    # ---------------------------------------------------------
    # 2ï¸ CatÃ©gorisation des compteurs
    # ---------------------------------------------------------
    def categorize_counters(self):
        duration = self.df_clean.groupby("counter_id")["datetime"].agg(["min","max"])
        duration["days"] = (duration["max"] - duration["min"]).dt.days + 1

        def categorize(days):
            if days >= 365:
                return "plus de 365 jours"
            elif days >= 200:
                return "200 jours ou plus"
            elif days < 100:
                return "moins de 100 jours"
            else:
                return "autres"

        duration["category"] = duration["days"].apply(categorize)
        self.duration = duration
        return duration

    # ---------------------------------------------------------
    # 3ï¸ Feature engineering
    # ---------------------------------------------------------
    def add_features(self, df: pd.DataFrame):
        df = df.copy()  # force une copie indÃ©pendante pour Ã©viter le warning
        df['rolling_3h'] = df.groupby('counter_id')['intensity'].transform(
            lambda x: x.rolling(3, min_periods=1).mean()
        )
        df['lag_1h'] = df.groupby('counter_id')['intensity'].shift(1)
        df['lag_24h'] = df.groupby('counter_id')['intensity'].shift(24)
        df['pct_change_1h'] = df.groupby('counter_id')['intensity'].pct_change()
        return df

    # ---------------------------------------------------------
    # 4ï¸ Fusion avec mÃ©tÃ©o
    # ---------------------------------------------------------
    def merge_with_weather(self, df: pd.DataFrame):
        if self.df_meteo is None:
            return df
        df['datetime'] = df['datetime'].dt.tz_convert(None)
        df_m = self.df_meteo.copy()
        df_m['datetime'] = pd.to_datetime(df_m['datetime']).dt.tz_localize(None)
        df_merged = df.merge(df_m, on='datetime', how='left')
        return df_merged

    # ---------------------------------------------------------
    # 5ï¸ Export des datasets
    # ---------------------------------------------------------
    def export_data(self,
                    path_clean="data_files/processed/data_clean.csv",
                    path_features="data_files/processed/features.csv"):

        # CrÃ©er les dossiers si inexistants
        os.makedirs(os.path.dirname(path_clean), exist_ok=True)
        os.makedirs(os.path.dirname(path_features), exist_ok=True)

        df_clean_copy = self.df_clean.copy()
        features_copy = df_clean_copy[['counter_id', 'datetime', 'intensity',
                                    'rolling_3h', 'lag_1h', 'lag_24h', 'pct_change_1h']].copy()

        df_clean_copy.to_csv(path_clean, index=False)
        features_copy.to_csv(path_features, index=False)

        print(f"Datasets exportÃ©s : {path_clean}, {path_features}")

    # ---------------------------------------------------------
    # 6ï¸ Pipeline complet
    # ---------------------------------------------------------
    def run_pipeline(self):
        self.clean_data()
        self.categorize_counters()
    
        # Filtrage compteurs par durÃ©e
        self.df_365 = self.df_clean[self.df_clean['counter_id'].isin(
            self.duration[self.duration['category'] == "plus de 365 jours"].index
        )]
        self.df_200 = self.df_clean[self.df_clean['counter_id'].isin(
            self.duration[self.duration['category'] == "200 jours ou plus"].index
        )]
        self.df_100 = self.df_clean[self.df_clean['counter_id'].isin(
            self.duration[self.duration['category'] == "moins de 100 jours"].index
        )]

        # Feature engineering
        self.df_clean = self.add_features(self.df_clean)
        self.df_365 = self.add_features(self.df_365)
        self.df_200 = self.add_features(self.df_200)
        self.df_100 = self.add_features(self.df_100)

        # Fusion mÃ©tÃ©o
        self.df_clean = self.merge_with_weather(self.df_clean)
        self.df_365 = self.merge_with_weather(self.df_365)
        self.df_200 = self.merge_with_weather(self.df_200)
        self.df_100 = self.merge_with_weather(self.df_100)

        # Export
        self.export_data()

        return {
            'df_clean': self.df_clean,
            'df_365': self.df_365,
            'df_200': self.df_200,
            'df_100': self.df_100,
            'duration': self.duration
        }

# ---------------------------------------------------------
# Bloc test CORRIGÃ‰
# ---------------------------------------------------------
if __name__ == "__main__":

    # --- 1. CHARGEMENT VÃ‰LO ---
    try:
        print("Chargement vÃ©lo...")
        # CRUCIAL : sep=';'
        df_velo = pd.read_csv("data_files/velo_data.csv", sep=';')
        
        # Nettoyage Date VÃ©lo : On gÃ¨re le '+00:00' (UTC) et on le retire pour avoir une date naÃ¯ve
        # df_velo['datetime'] = pd.to_datetime(df_velo['datetime'], utc=True).dt.tz_localize(None)
        
        print(f"âœ… VÃ©lo chargÃ© : {len(df_velo)} lignes")
        # Debug pour Ãªtre sÃ»r
        # print(df_velo.head(1)) 

    except FileNotFoundError:
        print("âš  Fichier velo_data.csv non trouvÃ© !")
        df_velo = pd.DataFrame()

    # --- 2. CHARGEMENT MÃ‰TÃ‰O ---
    try:
        print("Chargement mÃ©tÃ©o...")
        # CRUCIAL : sep=';' ET decimal=',' (sinon '5,8' devient du texte)
        df_meteo = pd.read_csv("data_files/meteo_mtp.csv", sep=';', decimal=',')
        
        # Nettoyage Date MÃ©tÃ©o : Format standard YYYY-MM-DD HH:MM:SS
        # df_meteo['datetime'] = pd.to_datetime(df_meteo['datetime'])
        
        # NOTE : Si vos donnÃ©es mÃ©tÃ©o sont en heure locale (Paris), dÃ©commentez les lignes suivantes
        # pour les convertir en UTC comme le vÃ©lo. Sinon, on suppose qu'elles sont dÃ©jÃ  synchro.
        # df_meteo['datetime'] = df_meteo['datetime'].dt.tz_localize('Europe/Paris', ambiguous=True).dt.tz_convert('UTC').dt.tz_localize(None)

        print(f"âœ… MÃ©tÃ©o chargÃ©e : {len(df_meteo)} lignes")

    except FileNotFoundError:
        print("âš  Fichier meteo_mtp.csv non trouvÃ© !")
        df_meteo = None

    # --- 3. LANCEMENT PIPELINE ---
    if not df_velo.empty:
        # On instancie la classe avec les DataFrames propres
        pipeline = VeloPipeline(df_velo, df_meteo)
        
        # On lance le traitement
        results = pipeline.run_pipeline()
        
        print("\nğŸ‰ Pipeline terminÃ© avec succÃ¨s !")
        print("AperÃ§u df_clean :")
        print(results['df_clean'].head())