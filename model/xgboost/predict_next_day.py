import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
import requests
from datetime import timedelta

def predict_next_day(path_data="data/processed/train_data_xgboost.csv", path_model="model/xgboost/saved/xgboost_velo.pkl"):
    print("ðŸ”® DÃ©marrage du moteur de prÃ©diction...")

    # 1. CHARGEMENT
    try:
        df_history = pd.read_csv(path_data, sep=';')
        model = joblib.load(path_model)
        print("âœ… ModÃ¨le et Historique chargÃ©s.")
    except Exception as e:
        print(f"âŒ Erreur de chargement : {e}")
        return

    # Conversion date
    df_history['datetime'] = pd.to_datetime(df_history['datetime'])
    df_history = df_history.sort_values('datetime')

    # 2. DÃ‰TERMINER LA DATE CIBLE (J+1 par rapport Ã  la fin des donnÃ©es)
    last_date_in_data = df_history['datetime'].max()
    target_date_start = last_date_in_data + timedelta(hours=1)
    # On veut prÃ©dire les 24 prochaines heures
    target_dates = pd.date_range(start=target_date_start, periods=24, freq='h')
    
    print(f"ðŸ“… PrÃ©diction pour la journÃ©e du : {target_dates[0].strftime('%Y-%m-%d')}")

    # 3. CONSTRUCTION DU DATAFRAME "FUTUR"
    # On doit crÃ©er une ligne pour chaque heure et chaque compteur
    unique_counters = df_history['counter_id_encoded'].unique()
    
    future_rows = []
    
    # Pour chaque heure de demain
    for dt in target_dates:
        # Pour chaque compteur
        for counter in unique_counters:
            
            # --- A. RÃ‰CUPÃ‰RATION DES LAGS (Le cÅ“ur du systÃ¨me) ---
            # Pour prÃ©dire demain 8h, j'ai besoin de la valeur d'aujourd'hui 8h (Lag 24)
            # Date de rÃ©fÃ©rence pour le Lag 24h
            ref_date_24h = dt - timedelta(hours=24)
            ref_date_1wk = dt - timedelta(days=7)
            
            # Recherche dans l'historique
            # On filtre sur le compteur et la date exacte
            # (En prod, on utiliserait une base de donnÃ©es SQL pour faire Ã§a vite)
            hist_counter = df_history[df_history['counter_id_encoded'] == counter]
            
            val_lag_24 = hist_counter.loc[hist_counter['datetime'] == ref_date_24h, 'intensity']
            val_lag_1wk = hist_counter.loc[hist_counter['datetime'] == ref_date_1wk, 'intensity']
            
            # SÃ©curitÃ© si donnÃ©es manquantes (on prend la moyenne du compteur)
            lag_24 = val_lag_24.values[0] if len(val_lag_24) > 0 else hist_counter['intensity'].mean()
            lag_1wk = val_lag_1wk.values[0] if len(val_lag_1wk) > 0 else lag_24
            
            # Rolling mean 4 jours (approximation avec lag 24 si calcul trop lourd)
            rolling_4d = lag_24 

            # --- B. DONNÃ‰ES TEMPORELLES ---
            hour = dt.hour
            day_of_week = dt.dayofweek
            month = dt.month
            
            # --- C. MÃ‰TÃ‰O (SIMULATION PRÃ‰VISION) ---
            # En prod, on appellerait l'API Open-Meteo ici.
            # Pour l'exemple, on prend la mÃ©tÃ©o de la veille (mÃ©thode "naÃ¯ve" souvent efficace)
            # ou des moyennes saisonniÃ¨res.
            temp = 15.0 # Exemple : il fera 15 degrÃ©s
            rain = 0.0  # Pas de pluie
            wind = 10.0 # Vent moyen
            
            # --- D. FÃ‰RIÃ‰S ---
            # On vÃ©rifie si la date cible est dans ton fichier fÃ©riÃ© (simplifiÃ© ici Ã  0)
            is_holiday = 0 
            
            # CrÃ©ation de la ligne
            row = {
                'counter_id_encoded': counter,
                'hour': hour,
                'day_of_week': day_of_week,
                'month': month,
                'is_weekend': 1 if day_of_week >= 5 else 0,
                # Encodage Cyclique
                'hour_sin': np.sin(2 * np.pi * hour / 24),
                'hour_cos': np.cos(2 * np.pi * hour / 24),
                'month_sin': np.sin(2 * np.pi * month / 12),
                'month_cos': np.cos(2 * np.pi * month / 12),
                'dow_sin': np.sin(2 * np.pi * day_of_week / 7),
                'dow_cos': np.cos(2 * np.pi * day_of_week / 7),
                # MÃ©tÃ©o
                'temperature_2m': temp,
                'precipitation': rain,
                'wind_speed_10m': wind,
                'lat': 43.6, # Ã€ affiner selon compteur si dispo
                'lon': 3.8,
                # Lags & Events
                'lag_24h': lag_24,
                'lag_48h': lag_24, # Approximation si on n'a pas tout l'historique chargÃ©
                'lag_1week': lag_1wk,
                'rolling_mean_4d': rolling_4d,
                'is_holiday': is_holiday,
                'is_major_event': 0 # Ã€ connecter Ã  ton fichier event scrapÃ©
            }
            future_rows.append(row)

    # CrÃ©ation du DataFrame X_future
    X_future = pd.DataFrame(future_rows)
    
    # On s'assure d'avoir les mÃªmes colonnes que lors de l'entraÃ®nement
    # XGBoost est trÃ¨s strict sur l'ordre des colonnes
    cols_when_model_built = model.get_booster().feature_names
    
    # On ajoute les colonnes manquantes avec 0 (sÃ©curitÃ©)
    for col in cols_when_model_built:
        if col not in X_future.columns:
            X_future[col] = 0
            
    # On rÃ©ordonne
    X_future = X_future[cols_when_model_built]

    # 4. PRÃ‰DICTION
    print("ðŸš€ Calcul des prÃ©dictions...")
    preds = model.predict(X_future)
    preds = np.clip(preds, 0, None).astype(int)
    
    # 5. RÃ‰SULTAT
    X_future['predicted_intensity'] = preds
    X_future['date'] = target_dates[0].date()
    
    # AgrÃ©gation pour affichage propre (Total par heure sur la ville)
    print("\nðŸš² PRÃ‰VISIONS POUR DEMAIN (Somme de tous les compteurs) :")
    summary = X_future.groupby('hour')['predicted_intensity'].sum()
    print(summary)
    
    # Sauvegarde
    X_future.to_csv("output/previsions_demain.csv", index=False, sep=';')
    print("\nðŸ’¾ DÃ©tail sauvegardÃ© dans 'output/previsions_demain.csv'")

if __name__ == "__main__":
    predict_next_day()