{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66273d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "def fusionner_csv_par_colonnes_robustes(\n",
    "    fichier_gauche_path: str,\n",
    "    fichier_droit_path: str,\n",
    "    colonne_cle: str,\n",
    "    type_jointure: str = 'inner'\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fusionne deux fichiers CSV par une colonne clé avec gestion d'erreurs.\n",
    "    Vérifie la présence des fichiers, l'existence de la clé, et le format de la clé.\n",
    "    \n",
    "    Args:\n",
    "        fichier_gauche_path: Chemin du premier fichier CSV.\n",
    "        fichier_droit_path: Chemin du second fichier CSV.\n",
    "        colonne_cle: Nom de la colonne à utiliser pour la jointure (ex: 'time').\n",
    "        type_jointure: Type de jointure ('inner', 'left', 'right', 'outer').\n",
    "                       \n",
    "    Returns:\n",
    "        Le DataFrame fusionné ou None en cas d'erreur critique.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres de lecture basés sur votre format habituel\n",
    "    params_lecture = {'sep': ';', 'decimal': ',', 'parse_dates': [colonne_cle]}\n",
    "    \n",
    "    # ------------------ 1. Gestion des erreurs de lecture/format ------------------\n",
    "    try:\n",
    "        if not os.path.exists(fichier_gauche_path) or not os.path.exists(fichier_droit_path):\n",
    "            print(\"ERREUR CRITIQUE : Un ou plusieurs chemins de fichiers sont introuvables.\")\n",
    "            return None\n",
    "            \n",
    "        df_gauche = pd.read_csv(fichier_gauche_path, **params_lecture)\n",
    "        df_droit = pd.read_csv(fichier_droit_path, **params_lecture)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR CRITIQUE lors de la lecture des fichiers (vérifiez le chemin ou les paramètres sep/decimal) : {e}\")\n",
    "        return None\n",
    "\n",
    "    # ------------------ 2. Gestion des erreurs de colonne clé ------------------\n",
    "    if colonne_cle not in df_gauche.columns:\n",
    "        print(f\"ERREUR : La colonne clé '{colonne_cle}' est absente du fichier de gauche.\")\n",
    "        return None\n",
    "    if colonne_cle not in df_droit.columns:\n",
    "        print(f\"ERREUR : La colonne clé '{colonne_cle}' est absente du fichier de droite.\")\n",
    "        return None\n",
    "        \n",
    "    # ------------------ 3. Gestion des erreurs de format de clé (Datetime) ------------------\n",
    "    # On vérifie que la colonne clé est de type datetime (après le parse_dates)\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_gauche[colonne_cle]):\n",
    "        print(f\"ATTENTION : La colonne clé '{colonne_cle}' du fichier de gauche n'est pas au format Datetime.\")\n",
    "        # Tentative de conversion si la lecture a échoué silencieusement\n",
    "        try:\n",
    "            df_gauche[colonne_cle] = pd.to_datetime(df_gauche[colonne_cle])\n",
    "        except:\n",
    "            print(f\"ERREUR : Impossible de convertir la clé '{colonne_cle}' du fichier de gauche en format Date/Heure.\")\n",
    "            return None\n",
    "\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_droit[colonne_cle]):\n",
    "        print(f\"ATTENTION : La colonne clé '{colonne_cle}' du fichier de droite n'est pas au format Datetime.\")\n",
    "        try:\n",
    "            df_droit[colonne_cle] = pd.to_datetime(df_droit[colonne_cle])\n",
    "        except:\n",
    "            print(f\"ERREUR : Impossible de convertir la clé '{colonne_cle}' du fichier de droite en format Date/Heure.\")\n",
    "            return None\n",
    "\n",
    "    # ------------------ 4. Fusion des DataFrames ------------------\n",
    "    try:\n",
    "        df_fusionne = pd.merge(\n",
    "            df_gauche,\n",
    "            df_droit,\n",
    "            on=colonne_cle,\n",
    "            how=type_jointure,\n",
    "            suffixes=('_gauche', '_droit')\n",
    "        )\n",
    "        print(f\"Fusion réussie avec la jointure '{type_jointure}' sur la clé '{colonne_cle}'.\")\n",
    "        return df_fusionne\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR : Échec de l'opération pd.merge : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f37190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERREUR CRITIQUE lors de la lecture des fichiers (vérifiez le chemin ou les paramètres sep/decimal) : Missing column provided to 'parse_dates': 'datetime'\n"
     ]
    }
   ],
   "source": [
    "fusionner_csv_par_colonnes_robustes(\n",
    "    \"df_162_clean.csv\",\n",
    "    \"csv_meteo.csv\",\n",
    "    \"datetime\",\n",
    "    'inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffccaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Fichier csv_meteo.csv chargé et clé 'datetime' prête.\n",
      "2. Fichier df_162_clean.csv chargé et clé 'datetime' prête.\n",
      "ERREUR lors de l'opération de fusion pd.merge : 'datetime'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_53685/1581243513.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     60\u001b[39m     print(df_fusionne.head())\n\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     63\u001b[39m     print(f\"ERREUR lors de l'opération de fusion pd.merge : {e}\")\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[32m~/velomag_montpellier/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32m~/velomag_montpellier/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32m~/velomag_montpellier/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32m~/velomag_montpellier/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'datetime'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Définition des Chemins et Clé ---\n",
    "fichier_meteo_path = 'csv_meteo.csv' # Le fichier avec la colonne 'time' (ou 'datetime' si renommé)\n",
    "fichier_clean_path = 'df_162_clean.csv'  # Le fichier avec la colonne 'datetime' (assumée)\n",
    "COLONNE_CLE = 'datetime'\n",
    "\n",
    "# Paramètres de lecture communs (basés sur votre fichier météo)\n",
    "# NOTE : Ces paramètres doivent être vérifiés et ajustés pour df_162_clean.csv si son format est différent.\n",
    "PARAMS_LECTURE_METEO = {'sep': ';', 'decimal': ','}\n",
    "\n",
    "# --- ÉTAPE 1 : Chargement et Harmonisation des Noms ---\n",
    "\n",
    "# Chargement du fichier 1 (ma_meteo_export.csv)\n",
    "try:\n",
    "    df_meteo = pd.read_csv(fichier_meteo_path, **PARAMS_LECTURE_METEO)\n",
    "    # Si l'utilisateur a confirmé avoir renommé 'time' en 'datetime' ailleurs, \n",
    "    # nous vérifions et renommons ici au cas où.\n",
    "    if 'time' in df_meteo.columns:\n",
    "        df_meteo.rename(columns={'time': COLONNE_CLE}, inplace=True)\n",
    "    \n",
    "    # Conversion explicite de la colonne clé en Datetime\n",
    "    # df_meteo[COLONNE_CLE] = pd.to_datetime(df_meteo[COLONNE_CLE])\n",
    "    print(f\"1. Fichier {fichier_meteo_path} chargé et clé '{COLONNE_CLE}' prête.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR lors du chargement ou de la préparation de {fichier_meteo_path} : {e}\")\n",
    "    # Si le fichier n'a ni 'time' ni 'datetime', l'opération échouera ici.\n",
    "    raise\n",
    "\n",
    "# Chargement du fichier 2 (df_162_clean.csv)\n",
    "try:\n",
    "    # Lecture, en supposant que df_162_clean utilise aussi le séparateur ';' et décimal ','\n",
    "    df_clean = pd.read_csv(fichier_clean_path, **PARAMS_LECTURE_METEO)\n",
    "    \n",
    "    # Conversion explicite de la colonne clé en Datetime\n",
    "    # Cela gère l'hypothèse où 'datetime' existe, mais n'est pas reconnu comme datetime par défaut.\n",
    "    # df_clean[COLONNE_CLE] = pd.to_datetime(df_clean[COLONNE_CLE])\n",
    "    print(f\"2. Fichier {fichier_clean_path} chargé et clé '{COLONNE_CLE}' prête.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR lors du chargement ou de la préparation de {fichier_clean_path}. Vérifiez le chemin, le séparateur (sep=';') et le décimal (decimal=',') : {e}\")\n",
    "    # Si la colonne 'datetime' n'existe toujours pas ou si le format de lecture est incorrect, l'erreur est là.\n",
    "    raise\n",
    "\n",
    "# --- ÉTAPE 2 : Fusion (Jointure Interne) ---\n",
    "try:\n",
    "    df_fusionne = pd.merge(\n",
    "        df_clean,\n",
    "        df_meteo,\n",
    "        on=COLONNE_CLE,\n",
    "        how='inner',\n",
    "        suffixes=('_clean', '_meteo')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n3. Fusion réussie. Jointure '{'inner'}' sur la clé '{COLONNE_CLE}'.\")\n",
    "    print(f\"Taille du DataFrame final : {len(df_fusionne)} lignes.\")\n",
    "    print(\"\\nAperçu du DataFrame fusionné :\")\n",
    "    print(df_fusionne.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERREUR lors de l'opération de fusion pd.merge : {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
